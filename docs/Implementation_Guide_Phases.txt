Phase-by-Phase Implementation Guide
Vantage Point: Detailed Technical Specifications for AI Coding Assistance

PHASE 1: AUTOMATED SCOUTING REPORT (Days 1-5)
Target: Category 2 MVP Submission

Day 1-2: Data Infrastructure Layer
Task 1.1: Project Structure Setup
Create the following directory structure:

vantage-point/ ├── backend/ │   ├── app/ │   │   ├── __init__.py │   │   ├── main.py                 # FastAPI application entry │   │   ├── models.py                # Pydantic data models │   │   ├── grid_client.py          # GRID API integration │   │   ├── analyzer.py             # Analytics engine │   │   └── rag_engine.py           # RAG pipeline │   ├── data/ │   │   ├── debug_cache/            # Cached match JSONs │   │   └── knowledge_base/         # Scraped strategy guides │   ├── scripts/ │   │   └── seed_match_data.py      # Data seeding script │   ├── tests/ │   │   └── test_analyzer.py        # Unit tests │   ├── requirements.txt │   └── .env                        # API keys ├── frontend/ │   ├── src/ │   │   ├── app/ │   │   │   ├── page.tsx            # Main dashboard │   │   │   └── layout.tsx          # Root layout │   │   ├── components/ │   │   │   ├── SearchBar.tsx │   │   │   ├── ReportView.tsx │   │   │   └── Charts.tsx │   │   └── hooks/ │   │       └── useScoutData.ts │   ├── public/ │   ├── package.json │   └── tailwind.config.ts └── README.md

Task 1.2: Backend Dependencies Installation
Create requirements.txt with the following packages:

fastapi==0.109.0 uvicorn[standard]==0.27.0 pydantic==2.5.3 pandas==2.1.4 numpy==1.26.3 requests==2.31.0 python-dotenv==1.0.0 langchain==0.1.0 langchain-groq==0.0.1 sentence-transformers==2.3.0 faiss-cpu==1.7.4 beautifulsoup4==4.12.3

Install command:
pip install -r requirements.txt

Task 1.3: GRID API Client Implementation
File: backend/app/grid_client.py

import os import json import requests from pathlib import Path from typing import List, Dict, Optional  class GridClient:     """     GRID API client with debug mode caching.     Supports both live API calls and local cache for development.     """          def __init__(self, api_key: str, debug_mode: bool = False):         self.api_key = api_key         self.debug_mode = debug_mode         self.base_url = "https://api.grid.gg/central-data/graphql"         self.cache_dir = Path("data/debug_cache")         self.cache_dir.mkdir(parents=True, exist_ok=True)          def fetch_team_matches(self, team_name: str, limit: int = 50) -> List[Dict]:         """         Fetch recent matches for a team.         In debug mode, reads from local cache.         In live mode, queries GRID GraphQL endpoint.         """         if self.debug_mode:             return self._load_from_cache(team_name)                  query = """         query TeamMatches($teamName: String!, $limit: Int!) {             matches(                 filter: {                      teams: { name: { eq: $teamName } }                     game: { title: { eq: "VALORANT" } }                 }                 limit: $limit                 orderBy: { field: START_TIME, direction: DESC }             ) {                 id                 startTime                 teams {                     id                     name                 }                 map {                     name                 }                 segments {                     segmentIndex                     winner { id }                     endReason                     duration                     plantLocation                 }                 players {                     id                     inGameName                     agent { name }                     playerStats {                         kills                         deaths                         assists                         acs                         economy                     }                 }             }         }         """                  variables = {"teamName": team_name, "limit": limit}                  response = requests.post(             self.base_url,             headers={"Authorization": f"Bearer {self.api_key}"},             json={"query": query, "variables": variables}         )                  if response.status_code != 200:             raise Exception(f"GRID API error: {response.status_code}")                  data = response.json()         matches = data.get("data", {}).get("matches", [])                  # Cache the response         self._save_to_cache(team_name, matches)                  return matches          def _load_from_cache(self, team_name: str) -> List[Dict]:         """Load matches from local JSON cache."""         cache_file = self.cache_dir / f"{team_name.lower()}_matches.json"                  if not cache_file.exists():             raise FileNotFoundError(                 f"No cache found for {team_name}. Run seed_match_data.py first."             )                  with open(cache_file, 'r') as f:             return json.load(f)          def _save_to_cache(self, team_name: str, matches: List[Dict]):         """Save matches to local JSON cache."""         cache_file = self.cache_dir / f"{team_name.lower()}_matches.json"         with open(cache_file, 'w') as f:             json.dump(matches, f, indent=2) 

Task 1.4: Data Seeding Script
File: backend/scripts/seed_match_data.py

import os from dotenv import load_dotenv from app.grid_client import GridClient  load_dotenv()  def seed_data():     """     Fetch and cache match data for development.     Run this script ONCE before starting development.     """     api_key = os.getenv("GRID_API_KEY")     if not api_key:         raise ValueError("GRID_API_KEY not found in .env file")          client = GridClient(api_key=api_key, debug_mode=False)          # List of teams to cache     teams = ["Cloud9", "Sentinels", "100 Thieves", "Team Liquid"]          for team in teams:         print(f"Fetching matches for {team}...")         matches = client.fetch_team_matches(team, limit=50)         print(f"  ✓ Cached {len(matches)} matches")          print("\nData seeding complete! Debug cache ready.")  if __name__ == "__main__":     seed_data() 

Run this script immediately after getting GRID API access:
python backend/scripts/seed_match_data.py

Day 3: Analytics Engine
Task 3.1: Data Normalization
File: backend/app/analyzer.py (Part 1)

import pandas as pd import numpy as np from typing import List, Dict  class ScoutingAnalyzer:     """     Analyzes match data to generate scouting reports.     """          def __init__(self, matches: List[Dict]):         self.matches = matches         self.df_rounds = None         self.df_players = None         self._normalize_data()          def _normalize_data(self):         """         Convert nested JSON to flat DataFrames.         Creates two primary tables: rounds and players.         """         rounds_data = []         players_data = []                  for match in self.matches:             match_id = match["id"]             map_name = match["map"]["name"]                          # Process segments (rounds)             for segment in match.get("segments", []):                 rounds_data.append({                     "match_id": match_id,                     "map_name": map_name,                     "round_number": segment["segmentIndex"],                     "winning_team_id": segment["winner"]["id"],                     "end_reason": segment["endReason"],                     "duration": segment["duration"],                     "plant_location": segment.get("plantLocation")                 })                          # Process players             for player in match.get("players", []):                 stats = player.get("playerStats", {})                 players_data.append({                     "match_id": match_id,                     "map_name": map_name,                     "player_id": player["id"],                     "player_name": player["inGameName"],                     "agent": player.get("agent", {}).get("name"),                     "kills": stats.get("kills", 0),                     "deaths": stats.get("deaths", 0),                     "assists": stats.get("assists", 0),                     "acs": stats.get("acs", 0),                     "economy": stats.get("economy", 0)                 })                  self.df_rounds = pd.DataFrame(rounds_data)         self.df_players = pd.DataFrame(players_data)          def get_win_rate(self, map_name: Optional[str] = None) -> float:         """Calculate overall or map-specific win rate."""         df = self.df_rounds                  if map_name:             df = df[df["map_name"] == map_name]                  if df.empty:             return 0.0                  # Assumes analyzing first team in match list         team_id = self.matches[0]["teams"][0]["id"]         wins = (df["winning_team_id"] == team_id).sum()                  return (wins / len(df)) * 100 

Task 3.2: Metric Calculations
File: backend/app/analyzer.py (Part 2)

    def get_site_preferences(self) -> Dict[str, float]:         """         Analyze which sites team attacks most frequently.         Returns dict like {"A": 65.0, "B": 35.0}         """         df = self.df_rounds[self.df_rounds["plant_location"].notna()]                  if df.empty:             return {}                  site_counts = df["plant_location"].value_counts()         total = site_counts.sum()                  return {             site: (count / total) * 100              for site, count in site_counts.items()         }          def get_aggression_index(self) -> Dict[str, any]:         """         Calculate playstyle based on round duration.         Returns classification and average duration.         """         avg_duration = self.df_rounds["duration"].mean()                  if avg_duration < 40:             style = "Rush"         elif avg_duration < 80:             style = "Default"         else:             style = "Slow/Default"                  return {             "style": style,             "avg_duration": round(avg_duration, 1),             "rush_rate": (self.df_rounds["duration"] < 40).sum() / len(self.df_rounds) * 100         }          def get_agent_composition(self) -> List[Dict[str, any]]:         """         Return top 5 most-picked agents with frequencies.         """         agent_counts = self.df_players["agent"].value_counts().head(5)         total_picks = len(self.df_players)                  return [             {                 "agent": agent,                 "pick_count": int(count),                 "pick_rate": round((count / total_picks) * 100, 1)             }             for agent, count in agent_counts.items()         ]          def get_economy_distribution(self) -> Dict[str, float]:         """         Classify rounds by economy state.         """         # Calculate average economy per round from player data         round_economy = self.df_players.groupby("match_id")["economy"].mean()                  eco = (round_economy < 2000).sum()         force = ((round_economy >= 2000) & (round_economy < 3900)).sum()         full = (round_economy >= 3900).sum()         total = len(round_economy)                  return {             "eco": round((eco / total) * 100, 1),             "force": round((force / total) * 100, 1),             "full": round((full / total) * 100, 1)         }          def generate_metrics_summary(self) -> Dict:         """         Aggregate all metrics into single report payload.         """         return {             "win_rate": self.get_win_rate(),             "site_preferences": self.get_site_preferences(),             "aggression": self.get_aggression_index(),             "agent_composition": self.get_agent_composition(),             "economy": self.get_economy_distribution()         } 

Day 4: AI/RAG Integration
Task 4.1: Knowledge Base Construction
File: backend/app/rag_engine.py (Part 1)

from langchain.document_loaders import WebBaseLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from sentence_transformers import SentenceTransformer import faiss import numpy as np from typing import List  class RAGEngine:     """     Retrieval-Augmented Generation for strategy insights.     """          def __init__(self):         self.embedder = SentenceTransformer('all-MiniLM-L6-v2')         self.index = None         self.documents = []         self._build_knowledge_base()          def _build_knowledge_base(self):         """         Scrape VALORANT strategy guides and create vector index.         """         # URLs of high-quality VALORANT strategy content         urls = [             "https://www.valorantzone.gg/guides/agent-counters",             "https://www.thespike.gg/tactics",             # Add more strategy guide URLs here         ]                  # Load and chunk documents         loader = WebBaseLoader(urls)         documents = loader.load()                  text_splitter = RecursiveCharacterTextSplitter(             chunk_size=1000,             chunk_overlap=200         )                  chunks = text_splitter.split_documents(documents)         self.documents = [chunk.page_content for chunk in chunks]                  # Create embeddings         embeddings = self.embedder.encode(self.documents)         embeddings = np.array(embeddings).astype('float32')                  # Build FAISS index         dimension = embeddings.shape[1]         self.index = faiss.IndexFlatL2(dimension)         self.index.add(embeddings)                  print(f"Knowledge base built: {len(self.documents)} chunks indexed") 

Task 4.2: LLM Integration
File: backend/app/rag_engine.py (Part 2)

    def retrieve_context(self, query: str, k: int = 3) -> List[str]:         """         Find most relevant strategy documents for query.         """         query_embedding = self.embedder.encode([query])         query_embedding = np.array(query_embedding).astype('float32')                  distances, indices = self.index.search(query_embedding, k)                  return [self.documents[idx] for idx in indices[0]]          def generate_insights(self, metrics: Dict, team_name: str) -> Dict[str, str]:         """         Generate natural language scouting report using LLM.         """         from langchain_groq import ChatGroq                  # Initialize Groq LLM         llm = ChatGroq(             model="llama3-70b-8192",             temperature=0.3,             groq_api_key=os.getenv("GROQ_API_KEY")         )                  # Generate four sections         sections = {}                  # 1. Strategies         strategy_query = f"VALORANT {metrics['aggression']['style']} playstyle strategies"         strategy_context = self.retrieve_context(strategy_query)                  prompt = f"""You are a professional VALORANT analyst. Based on these metrics: - Team: {team_name} - Playstyle: {metrics['aggression']['style']} (avg {metrics['aggression']['avg_duration']}s rounds) - Win Rate: {metrics['win_rate']:.1f}%  Write a 2-3 sentence strategic overview of this team's playstyle. Keep it concise and specific to the data provided."""                  sections["strategies"] = llm.invoke(prompt).content                  # 2. Tendencies         site_pref = max(metrics['site_preferences'].items(), key=lambda x: x[1])         prompt = f"""Team {team_name} plants the spike at Site {site_pref[0]} {site_pref[1]:.0f}% of the time. Their agent pool includes: {', '.join([a['agent'] for a in metrics['agent_composition'][:3]])}.  Write 2-3 sentences describing their tactical tendencies."""                  sections["tendencies"] = llm.invoke(prompt).content                  # 3. Compositions         agents = metrics['agent_composition']         prompt = f"""Analyze this agent composition pattern: {chr(10).join([f"- {a['agent']}: {a['pick_rate']}%" for a in agents[:5]])}  Write 2-3 sentences about their composition strategy and role balance."""                  sections["compositions"] = llm.invoke(prompt).content                  # 4. How to Win (RAG-powered)         weakness_query = f"Counter {agents[0]['agent']} and {agents[1]['agent']} VALORANT"         counter_context = self.retrieve_context(weakness_query, k=5)                  prompt = f"""You are a coach preparing for Team {team_name}. They favor {site_pref[0]} site ({site_pref[1]:.0f}%) with {metrics['aggression']['style']} pacing.  Based on these counter-strategies: {chr(10).join(counter_context[:2])}  Provide 3-4 specific actionable recommendations to beat this team. Focus on: map control, agent counters, and timing."""                  sections["how_to_win"] = llm.invoke(prompt).content                  return sections 



Day 5: Frontend Development
Task 5.1: Next.js Setup
Initialize Next.js project:

npx create-next-app@latest frontend --typescript --tailwind --app cd frontend npm install recharts lucide-react @radix-ui/react-select npx shadcn-ui@latest init

Task 5.2: Main Dashboard Component
File: frontend/src/app/page.tsx

"use client"  import { useState } from 'react' import SearchBar from '@/components/SearchBar' import ReportView from '@/components/ReportView' import { useScoutData } from '@/hooks/useScoutData'  export default function Dashboard() {   const [teamName, setTeamName] = useState('')   const { data, loading, error, fetchReport } = useScoutData()      const handleSearch = (team: string) => {     setTeamName(team)     fetchReport(team)   }      return (     <div className="min-h-screen bg-slate-950 text-white">       <div className="container mx-auto px-4 py-8">         <header className="mb-12 text-center">           <h1 className="text-5xl font-bold mb-4 bg-gradient-to-r from-blue-400 to-cyan-300 text-transparent bg-clip-text">             Vantage Point           </h1>           <p className="text-slate-400 text-lg">             AI-Powered VALORANT Intelligence Platform           </p>         </header>                  <SearchBar onSearch={handleSearch} />                  {loading && (           <div className="flex justify-center items-center h-64">             <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-500" />           </div>         )}                  {error && (           <div className="bg-red-900/20 border border-red-500 rounded-lg p-4 text-center">             <p className="text-red-400">{error}</p>           </div>         )}                  {data && <ReportView data={data} teamName={teamName} />}       </div>     </div>   ) }

Task 5.3: FastAPI Backend Integration
File: backend/app/main.py

from fastapi import FastAPI, HTTPException from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel from dotenv import load_dotenv import os  from app.grid_client import GridClient from app.analyzer import ScoutingAnalyzer from app.rag_engine import RAGEngine  load_dotenv()  app = FastAPI(title="Vantage Point API")  # CORS for frontend app.add_middleware(     CORSMiddleware,     allow_origins=["http://localhost:3000"],     allow_credentials=True,     allow_methods=["*"],     allow_headers=["*"], )  # Initialize components grid_client = GridClient(     api_key=os.getenv("GRID_API_KEY"),     debug_mode=os.getenv("DEBUG_MODE", "false").lower() == "true" ) rag_engine = RAGEngine()  class ScoutRequest(BaseModel):     team_name: str     map_filter: str | None = None  @app.post("/api/scout") async def generate_scout_report(request: ScoutRequest):     """     Generate automated scouting report for opponent team.     """     try:         # Fetch match data         matches = grid_client.fetch_team_matches(request.team_name, limit=50)                  if not matches:             raise HTTPException(status_code=404, detail="Team not found")                  # Filter by map if specified         if request.map_filter:             matches = [m for m in matches if m["map"]["name"] == request.map_filter]                  # Analyze data         analyzer = ScoutingAnalyzer(matches)         metrics = analyzer.generate_metrics_summary()                  # Generate AI insights         insights = rag_engine.generate_insights(metrics, request.team_name)                  return {             "team_name": request.team_name,             "matches_analyzed": len(matches),             "metrics": metrics,             "insights": insights         }          except Exception as e:         raise HTTPException(status_code=500, detail=str(e))  @app.get("/api/health") async def health_check():     return {"status": "healthy", "debug_mode": grid_client.debug_mode} 

Start backend server:
uvicorn app.main:app --reload --port 8000



PHASE 2: ASSISTANT COACH UPGRADE (Days 6-10)
Target: Category 1 Extension (Optional)

Day 6-7: Granular Event Data
Task 6.1: Extended GRID Query
Add to backend/app/grid_client.py:

    def fetch_match_details(self, match_id: str) -> Dict:         """         Fetch granular event-level data for specific match.         Includes kill feed, buy phase, ability usage.         """         query = """         query MatchDetails($matchId: ID!) {             match(id: $matchId) {                 id                 startTime                 map { name }                 segments {                     segmentIndex                     winner { id }                     duration                     events {                         timestamp                         type                         player { id, inGameName }                         victim { id, inGameName }                         weapon                         damageDealt                     }                 }                 players {                     id                     inGameName                     agent { name, role }                     playerStats {                         kills                         deaths                         firstBloods                         acs                         kast                     }                     buyPhase {                         roundNumber                         weapon                         armor                         credits                     }                 }             }         }         """                  variables = {"matchId": match_id}                  response = requests.post(             self.base_url,             headers={"Authorization": f"Bearer {self.api_key}"},             json={"query": query, "variables": variables}         )                  if response.status_code != 200:             raise Exception(f"GRID API error: {response.status_code}")                  return response.json()["data"]["match"] 

Day 8: Error Detection Logic
Task 8.1: Micro-Error Detection
Create new file: backend/app/coach_analyzer.py

import pandas as pd from typing import List, Dict  class CoachAnalyzer:     """     Detects micro-errors and calculates impact scores.     """          def __init__(self, match_data: Dict):         self.match_data = match_data         self.errors = []          def detect_free_deaths(self, segment_data: Dict) -> List[Dict]:         """         Identify deaths within first 15s with 0 impact.         """         free_deaths = []                  for event in segment_data.get("events", []):             if event["type"] == "KILL":                 if event["timestamp"] < 15 and event.get("damageDealt", 0) == 0:                     free_deaths.append({                         "round": segment_data["segmentIndex"],                         "player": event["victim"]["inGameName"],                         "timestamp": event["timestamp"],                         "error_type": "FREE_DEATH",                         "impact_score": 8  # High impact                     })                  return free_deaths          def detect_bad_economy(self, buy_data: List[Dict]) -> List[Dict]:         """         Flag force buys when team has insufficient credits.         """         bad_buys = []                  for buy in buy_data:             if 2000 <= buy["credits"] < 3900:                 # Check if full team coordinated force or solo mistake                 bad_buys.append({                     "round": buy["roundNumber"],                     "player": buy["player"],                     "credits": buy["credits"],                     "weapon": buy["weapon"],                     "error_type": "BAD_ECONOMY",                     "impact_score": 6                 })                  return bad_buys          def detect_role_failures(self, player_stats: Dict, role: str) -> List[Dict]:         """         Check role-specific performance failures.         """         failures = []                  if role == "Duelist":             # Low first blood rate             fb_rate = (player_stats["firstBloods"] / 24) * 100             if fb_rate < 15:                 failures.append({                     "player": player_stats["inGameName"],                     "error_type": "DUELIST_PASSIVE",                     "metric": f"FB%: {fb_rate:.1f}",                     "impact_score": 7                 })                  elif role == "Controller":             # Dying first too often (should survive)             kast = player_stats.get("kast", 0)             if kast < 65:                 failures.append({                     "player": player_stats["inGameName"],                     "error_type": "CONTROLLER_DEATH",                     "metric": f"KAST: {kast}%",                     "impact_score": 9  # Critical                 })                  return failures          def calculate_impact_correlation(self, round_results: List[bool]) -> float:         """         Correlate high-impact error rounds with losses.         """         # Simplified correlation calculation         error_rounds = [i for i, errors in enumerate(self.errors) if errors]         loss_rounds = [i for i, result in enumerate(round_results) if not result]                  overlap = len(set(error_rounds) & set(loss_rounds))                  if not error_rounds:             return 0.0                  return (overlap / len(error_rounds)) * 100 

Day 9-10: Coach UI Components
Task 9.1: Timeline Component
File: frontend/src/components/Timeline.tsx

import { useState } from 'react' import ErrorModal from './ErrorModal'  interface Round {   number: number   result: 'W' | 'L' | 'D'   errors: Array<{     type: string     player: string     timestamp: number     description: string   }> }  export default function Timeline({ rounds }: { rounds: Round[] }) {   const [selectedRound, setSelectedRound] = useState<Round | null>(null)      return (     <div className="space-y-4">       <h3 className="text-xl font-semibold text-blue-400">Round Timeline</h3>              <div className="flex gap-2 flex-wrap">         {rounds.map((round) => (           <button             key={round.number}             onClick={() => setSelectedRound(round)}             className={`               w-12 h-12 rounded-lg font-semibold transition-all               ${round.result === 'W'                  ? 'bg-green-600 hover:bg-green-500'                  : 'bg-red-600 hover:bg-red-500'               }               ${round.errors.length > 0 && 'ring-2 ring-yellow-400'}             `}           >             {round.number}           </button>         ))}       </div>              {selectedRound && (         <ErrorModal           round={selectedRound}           onClose={() => setSelectedRound(null)}         />       )}     </div>   ) }

Task 9.2: Feature Toggle
Add to backend/app/main.py:

@app.post("/api/coach") async def generate_coach_report(request: CoachRequest):     """     Generate match-specific coaching report (Category 1).     """     try:         match_data = grid_client.fetch_match_details(request.match_id)                  coach = CoachAnalyzer(match_data)         errors = coach.detect_all_errors()         impact = coach.calculate_impact_correlation(match_data["round_results"])                  return {             "match_id": request.match_id,             "timeline": coach.generate_timeline(),             "errors": errors,             "impact_score": impact,             "recommendations": rag_engine.generate_coaching_tips(errors)         }          except Exception as e:         raise HTTPException(status_code=500, detail=str(e))

FINAL CHECKLIST
1. Test end-to-end flow with cached data
2. Validate metrics against VLR.gg public stats
3. Record 3-minute demo video showing both modes
4. Create README with setup instructions
5. Add MIT license to repository
6. Deploy to public GitHub repository
7. Submit to Devpost before February 3, 2026

